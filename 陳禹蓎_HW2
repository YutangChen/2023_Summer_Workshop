HW2: Assignment 1
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Load the California Housing dataset
data = fetch_california_housing()
X = data.data
y = data.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a linear regression model on the training set
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluate the model on the test set using Mean Squared Error (MSE)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error on Test Set: {mse}")

# Predict the price of a new house given its features
new_house_features = np.array([[8.3252, 41.0, 6.0, 1.0, 5.0, 3.0, 126.0, 8.3252, 15.0, 1.0, 5.0, 7.0, 2.0]])
predicted_price = model.predict(new_house_features)
print(f"Predicted Price of New House: {predicted_price[0]}")


HW2: Assignment 2
import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the handwritten digit dataset
data = load_digits()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply Linear Discriminant Analysis (LDA) for feature extraction
lda = LinearDiscriminantAnalysis()
X_train_lda = lda.fit_transform(X_train, y_train)
X_test_lda = lda.transform(X_test)

# Train a classifier on the transformed training data (e.g., k-nearest neighbors)
classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(X_train_lda, y_train)

# Test the classifier on the transformed test data
y_pred = classifier.predict(X_test_lda)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the Classifier: {accuracy}")

HW2: Assignment3
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
import graphviz

# Load the Iris dataset
data = load_iris()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a decision tree classifier on the training data
classifier = DecisionTreeClassifier(random_state=42)
classifier.fit(X_train, y_train)

# Test the classifier on the test data
y_pred = classifier.predict(X_test)

# Calculate accuracy on the test set
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy of the Decision Tree Classifier: {accuracy}")

# Visualize the decision tree
dot_data = tree.export_graphviz(classifier, out_file=None, 
                                feature_names=data.feature_names,  
                                class_names=data.target_names,
                                filled=True, rounded=True, special_characters=True)
graph = graphviz.Source(dot_data)

HW2:Assignment4
import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load the digits dataset
data = load_digits()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an SVM classifier on the training data
classifier = SVC(kernel='linear', C=1.0, random_state=42)
classifier.fit(X_train, y_train)

# Test the classifier on the test data
y_pred = classifier.predict(X_test)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the SVM Classifier: {accuracy}")


HW2:Assignment5
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the Iris dataset
data = load_iris()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a KNN classifier on the training data
classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(X_train, y_train)

# Test the classifier on the test data
y_pred = classifier.predict(X_test)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the KNN Classifier: {accuracy}")




HW3:Assigment 6:
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA

# Load the digits dataset
data = load_digits()
X = data.data
y = data.target

# Apply PCA to reduce dimensionality
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Visualize the reduced data in a 2D scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)
plt.colorbar(label='Digit Label')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Digits Dataset')
plt.show()

HW3:Assignment7:
import numpy as np
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import ShuffleSplit, cross_val_score

from mne import Epochs, pick_types, events_from_annotations
from mne.channels import make_standard_montage
from mne.io import concatenate_raws, read_raw_edf
from mne.datasets import eegbci
from mne.decoding import CSP

# Define subject and runs
subject = 1
runs = [6, 10, 14]  # motor imagery: hands vs feet

# Load EEG data
raw_fnames = eegbci.load_data(subject, runs)

raws = [read_raw_edf(f, preload=True) for f in raw_fnames]
raw = concatenate_raws(raws)

# Apply band-pass filter
raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')

# Define event IDs
event_id = dict(hands=2, feet=3)

# Extract events and annotations
events, _ = events_from_annotations(raw, event_id=dict(T1=2, T2=3))

# Create epochs
epochs = Epochs(raw, events, event_id, tmin=1, tmax=4, baseline=None, detrend=1,
                picks=pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False),
                preload=True)

# Apply CSP algorithm for feature extraction
csp = CSP(n_components=4, reg='ledoit_wolf')
csp.fit(epochs)

# Define X and y for classification
X = csp.transform(epochs.get_data())
y = epochs.events[:, -1]

# Create a pipeline with CSP and Linear Discriminant Analysis
clf = Pipeline([('CSP', csp), ('LDA', LinearDiscriminantAnalysis())])

# Define cross-validation parameters
cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)

# Perform cross-validation and calculate mean accuracy
scores = cross_val_score(clf, X, y, cv=cv, n_jobs=1)
mean_accuracy = np.mean(scores)

print(f"Mean Accuracy: {mean_accuracy:.2f}")
